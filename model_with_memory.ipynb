{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086e7d2d",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "The main assignment of this course is the report describing your Conversational AI final project. This project aims to develop two conversational agents that communicate with each other. One of them would simulate a User (traveler) interested in booking a hotel or restaurant based on specific preferences and constraints. The other would be the Assistant who helps the user find an adequate business vendor and points out their pros and cons based on prior reviews. \n",
    "\n",
    "__Project requirements__ \\\n",
    "The two conversational agents should be designed in a way that fits their purpose. \\\n",
    "At least one of the agents should be fine-tuned. \\\n",
    "You should explore two different versions of the Assistant agent. Think of using different fine-tuning or prompting approaches here. \\\n",
    "At least one agent should consult the knowledge base with reviews. \\\n",
    "Use two different personas for the User, which you can define using the Big-5 personality traits Links to an external site. or simulate your own traveler types.\n",
    "Optionally, for extra points: enhance the system further by incorporating memory. This is for extra points since we didn't cover it in the assignments, however, here Links to an external site. is a user-friendly notebook for working with memory using Mem0. Note that showing the effect of memory requires the setup to be designed in a corresponding way (e.g., the conversations need to be organized into sessions). \\\n",
    "Design N (at least 10) histories to initiate the conversation. \\\n",
    "Incorporate a mechanism to stop the conversation. The conversation should stop once the User expresses satisfaction after receiving a recommendation that fits the requirements.\n",
    "\n",
    "The success of the agents should be evaluated in two ways: \\\n",
    "Using objective metrics: number of turns before completion, length of the conversation (number of tokens), etc. \\\n",
    "Using subjective evaluation metrics, such as those in Assignment 3, operationalized with human subjects and an LLM as a judge. You could focus on optimizing for short, informative, or pleasant conversations, for example. Ensure that you include an evaluation of how often the Assistant actually fulfilled the User's request.\n",
    "All project choices: design of the agents, of the conversations, the evaluation, and the experiments need to be clearly motivated, well-explained, and supported with citations where relevant. The evaluation may or may not show that your motivation/expectation was correct - there will be no point deduction for this, but if there is a mismatch between your expectations and your findings, you are expected to reflect on why this may be.\n",
    "\n",
    "__Report structure__ \\\n",
    "Title and all author names \\\n",
    "Abstract summarizing the research question, method, and main findings \\\n",
    "Introduction section with a background to the problem addressed in this final assignment \\\n",
    "Methodology - description of the methods you used and how they work, including a motivation for their design. \\\n",
    "Experimental setup - with details on the data, evaluation metrics, parameter values, and implementation environment. \\\n",
    "Results section presenting the experimental questions and the corresponding outcomes of the analysis, including visualizations of the results as figures or tables. \\\n",
    "Conclusions section with: \\\n",
    "Summary of the findings and a discussion of their implications \\\n",
    "Limitations of your research approach, together with the envisioned future work \\\n",
    "Division of labor - 1 paragraph that describes how the implementation and the report writing were split among the team members. \\\n",
    "Statement of use of generative AI - if you used generative AI, indicate for what purpose and to what extent. \\\n",
    "References (tip: use the LaTeX/BibTeX reference system,  examples are in the template below) \\\n",
    "Further specification \\\n",
    "You use Springer style formatting in the style of the Springer Publications format for Lecture Notes in Computer Science (LNCS). For details on the LNCS style, see Springer’s Author InstructionsLinks to an external site. \\\n",
    "You use LaTeX with OverleafLinks to an external site. \\\n",
    "The easiest is probably to start from this Overleaf LCNS template. \\\n",
    "The maximum page length is 12 pages. References and appendices don't count towards the limit. \\\n",
    "Check the rubric before you start. \\\n",
    "The deadline is strict, with a full point deduction for every day you are late. In the event of special personal, medical, or other issues, please notify us before the deadline to determine if we can find a solution. \\\n",
    "Note: footnotes with references to websites can also be seen as related work in case they refer to original work. \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588adcba",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "Assistant\n",
    "- finetune a model (domain specific)\n",
    "- add knowledge to a model \n",
    "- (use an ontology if still time)\n",
    "\n",
    "User\n",
    "- two different personalities with prompting\n",
    "    - fiendly/polite american vs. staight forward\n",
    "    - more detail vs. more simple \n",
    "\n",
    "General\n",
    "- add memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2aec7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import List\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, pipeline, BitsAndBytesConfig\n",
    "import transformers, trl, peft\n",
    "import torch\n",
    "import random\n",
    "torch.manual_seed(3407); random.seed(3407); np.random.seed(3407)\n",
    "\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from peft import PeftConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e57540",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412b74d",
   "metadata": {},
   "source": [
    "## Get all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9c0b0",
   "metadata": {},
   "source": [
    "delete the whole \"data\" folder and make a new, empty \"data\" folder before running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dce7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'dstc11-track5'...\n"
     ]
    }
   ],
   "source": [
    "def setup_repo(repo_url: str, repo_name: str, work_dir: str = \"data\"):\n",
    "    os.chdir(work_dir)\n",
    "    \n",
    "    # Remove repo if it exists\n",
    "    if os.path.exists(os.path.join(work_dir, repo_name)):\n",
    "        shutil.rmtree(os.path.join(work_dir, repo_name))\n",
    "    \n",
    "    # Clone repo\n",
    "    subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
    "    \n",
    "    # Move into repo/data\n",
    "    os.chdir(os.path.join(repo_name, \"data\"))\n",
    "\n",
    "\n",
    "setup_repo(\"https://github.com/lkra/dstc11-track5.git\", \"dstc11-track5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729f6476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./knowledge_aug_reviews.json\n",
      "./output_schema.json\n",
      "./knowledge_aug_domain_reviews.json\n",
      "./README.md\n",
      "./knowledge.json\n",
      "./test/labels.json\n",
      "./test/logs.json\n",
      "./train/labels.json\n",
      "./train/logs.json\n",
      "./train/logs_bkp.json\n",
      "./train/bkp/labels.json\n",
      "./train/bkp/logs.json\n",
      "./val/labels.json\n",
      "./val/logs.json\n"
     ]
    }
   ],
   "source": [
    "## List all files in the current directory iteratively:\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b307d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train/logs.json', 'r') as f:\n",
    "    train_ds=json.load(f)\n",
    "\n",
    "with open('train/labels.json', 'r') as f:\n",
    "    labels=json.load(f)\n",
    "\n",
    "with open('knowledge.json', 'r') as f:\n",
    "    knowledge_base=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5be8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dialogue(dialogue: List[dict]) -> List[dict]: \n",
    "    \"\"\"\n",
    "    Args:\n",
    "    dialogue (List[dict]): A list of dictionaries where each dictionary contains two keys:\n",
    "        - 'speaker' (str): A string indicating the speaker of the turn ('U' for user, 'S' for system).\n",
    "        - 'text' (str): The text spoken by the respective speaker.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A new array with a specific role and content\n",
    "\n",
    "    \"\"\"\n",
    "    # Your solution here\n",
    "    messages=[]\n",
    "    messages.append({\"role\": \"system\", \"content\": \"You are an assistant.\"})\n",
    "    for dialogue_element in dialogue:\n",
    "        role = \"user\" if dialogue_element['speaker'] == 'U' else \"system\"\n",
    "        messages.append({\"role\": role, \"content\": dialogue_element['text']})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae8e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 16897\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reformat_dataset(dataset, labels_dataset): \n",
    "    reformatted_dataset = {\n",
    "        \"messages\": []\n",
    "    }\n",
    "    for sample_index in range(len(dataset)): \n",
    "        # Your solution here\n",
    "        try:\n",
    "            sample_dialogue = format_dialogue(dataset[sample_index])\n",
    "            sample_response = labels_dataset[sample_index]['response']\n",
    "            sample_dialogue.append({\"role\": \"system\", \"content\": sample_response})\n",
    "            \n",
    "            reformatted_dataset[\"messages\"].append(sample_dialogue)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "        \n",
    "    return reformatted_dataset\n",
    "\n",
    "reformatted_dataset = reformat_dataset(train_ds, labels)\n",
    "dataset = Dataset.from_dict(reformatted_dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdcd20f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 2129\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 2798\n",
       " }))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_dataset_split(split: str) -> Dataset: \n",
    "    \"\"\"Loads, reformats, and processes a dataset split for model training or evaluation.\n",
    "\n",
    "    This function loads a dataset split (e.g., 'val', 'test') and generates a dataset for it, similar to what we had for the train split.\n",
    "\n",
    "    Args:\n",
    "        split (str): The name of the dataset split to process\n",
    "\n",
    "    Returns:\n",
    "        dataset: A HuggingFace `Dataset` object that contains the preprocessed and reformatted data for the specified split.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(f'{split}/logs.json', 'r') as f:\n",
    "        data=json.load(f)\n",
    "\n",
    "    with open(f'{split}/labels.json', 'r') as f:\n",
    "        labels=json.load(f)\n",
    "\n",
    "    data_ds = reformat_dataset(data, labels)\n",
    "    new_dataset = Dataset.from_dict(data_ds)\n",
    "    \n",
    "    return new_dataset\n",
    "    \n",
    "\n",
    "validation_ds = process_dataset_split(\"val\")\n",
    "test_ds = process_dataset_split(\"test\")\n",
    "\n",
    "validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8b9e9",
   "metadata": {},
   "source": [
    "## data preparation user finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89be8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dialogue_user(dialogue: List[dict]) -> List[dict]: \n",
    "    \"\"\"\n",
    "    Args:\n",
    "    dialogue (List[dict]): A list of dictionaries where each dictionary contains two keys:\n",
    "        - 'speaker' (str): A string indicating the speaker of the turn ('U' for user, 'S' for system).\n",
    "        - 'text' (str): The text spoken by the respective speaker.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A new array with a specific role and content\n",
    "\n",
    "    \"\"\"\n",
    "    # Your solution here\n",
    "    messages=[]\n",
    "    messages.append({\"role\": \"system\", \"content\": \"You are a user simulator.\"})\n",
    "    for dialogue_element in dialogue:\n",
    "        role = \"assistant\" if dialogue_element['speaker'] == 'U' else \"user\" #roles swapped so it learns to behave like a user\n",
    "        messages.append({\"role\": role, \"content\": dialogue_element['text']})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733fdb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 32604\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reformat_dataset_user(dataset): \n",
    "    reformatted_dataset = {\n",
    "        \"messages\": []\n",
    "    }\n",
    "    for sample_index in range(len(dataset)):\n",
    "    #for sample_index in range(1):\n",
    "        try:\n",
    "            sample_dialogue = format_dialogue(dataset[sample_index][:-1]) # exclude last user message so system learns to respond as a user\n",
    "            sample_response = dataset[sample_index][-1]['text'] #use original last user message as response\n",
    "            sample_dialogue.append({\"role\": \"assistant\", \"content\": sample_response})\n",
    "            \n",
    "            reformatted_dataset[\"messages\"].append(sample_dialogue)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return reformatted_dataset\n",
    "\n",
    "\n",
    "reformatted_dataset_user = reformat_dataset_user(train_ds)\n",
    "dataset_user = Dataset.from_dict(reformatted_dataset_user)\n",
    "dataset_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310d26b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 2129\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 2798\n",
       " }))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_dataset_split_user(split: str) -> Dataset: \n",
    "    \"\"\"Loads, reformats, and processes a dataset split for model training or evaluation.\n",
    "\n",
    "    This function loads a dataset split (e.g., 'val', 'test') and generates a dataset for it, similar to what we had for the train split.\n",
    "\n",
    "    Args:\n",
    "        split (str): The name of the dataset split to process\n",
    "\n",
    "    Returns:\n",
    "        dataset: A HuggingFace `Dataset` object that contains the preprocessed and reformatted data for the specified split.\n",
    "\n",
    "    \"\"\"\n",
    "    with open(f'{split}/logs.json', 'r') as f:\n",
    "        data=json.load(f)\n",
    "\n",
    "    data_ds = reformat_dataset(data)\n",
    "    new_dataset = Dataset.from_dict(data_ds)\n",
    "    \n",
    "    return new_dataset\n",
    "    \n",
    "\n",
    "validation_ds_user = process_dataset_split(\"val\")\n",
    "test_ds_user = process_dataset_split(\"test\")\n",
    "\n",
    "validation_ds_user, test_ds_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaeb6b2",
   "metadata": {},
   "source": [
    "Results from the finetuning:\n",
    "\n",
    "finetuned2.1: \\\n",
    "TrainOutput(global_step=2113, training_loss=1.3732818416436587, metrics={'train_runtime': 6148.8185, 'train_samples_per_second': 2.748, 'train_steps_per_second': 0.344, 'total_flos': 4.201868035718554e+16, 'train_loss': 1.3732818416436587, 'entropy': 1.2068944639629788, 'num_tokens': 3938417.0, 'mean_token_accuracy': 0.6782568560706245, 'epoch': 1.0})\n",
    "\n",
    "finetuned2.2: \\\n",
    "TrainOutput(global_step=2113, training_loss=1.1545771166886756, metrics={'train_runtime': 6163.3328, 'train_samples_per_second': 2.742, 'train_steps_per_second': 0.343, 'total_flos': 4.219805159713382e+16, 'train_loss': 1.1545771166886756, 'entropy': 1.1386982864803739, 'num_tokens': 3955363.0, 'mean_token_accuracy': 0.6888072027100457, 'epoch': 1.0})\n",
    "\n",
    "We will proceed with the model from finetuned 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24134a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.78s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "#loading second finetuned model/ assistat\n",
    "base_model_id = \"Qwen/Qwen3-1.7B\"\n",
    "adapter_path  = \"/Users/benutzer/Documents/GitHub/CAI/outputs2/adapter2\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n",
    "model_base = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "model_base_for_adapter = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "finetuned_assitant = PeftModel.from_pretrained(model_base_for_adapter, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5778646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.40s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.59s/it]\n"
     ]
    }
   ],
   "source": [
    "#loading finetuned user\n",
    "base_model_id = \"Qwen/Qwen3-1.7B\"\n",
    "adapter_path_user  = \"/Users/benutzer/Documents/GitHub/CAI/outputsUser/adapterUser\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)\n",
    "model_base = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "model_base_for_adapter = AutoModelForCausalLM.from_pretrained(base_model_id, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "finetuned_user = PeftModel.from_pretrained(model_base_for_adapter, adapter_path_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f46c96",
   "metadata": {},
   "source": [
    "## Create agent 1: Assistant 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de01ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'content': 'You are an assistant.', 'role': 'system'},\n",
       "  {'content': \"I'm looking to stay at a 3 star hotel in the north.\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'Sorry, I have no results for that query. Would you like to try a different area of town?',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Are there any moderate priced hotels in the North?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Yes I have two. Would you like me to book one?',\n",
       "   'role': 'system'},\n",
       "  {'content': 'I need a hotel to include free parking; does either have that?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Yes both of them have free parking.', 'role': 'system'},\n",
       "  {'content': 'Which one would you recommend?', 'role': 'user'},\n",
       "  {'content': 'How about the Ashley hotel?', 'role': 'system'},\n",
       "  {'content': 'Is the Ashley hotel a 3 star hotel?', 'role': 'user'},\n",
       "  {'content': 'the ashley is actually a 2 star hotel.', 'role': 'system'},\n",
       "  {'content': 'Does this hotel have rooms with a good view of the neighborhood?',\n",
       "   'role': 'user'}],\n",
       " {'content': 'Apparently it does according to previous customers, they say that the view is beautiful especially on the higher floors.',\n",
       "  'role': 'system'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = test_ds[0]['messages'][:-1]\n",
    "response = test_ds[0]['messages'][-1]\n",
    "\n",
    "dialogue, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4464b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Model:  Yes, guests have been pleased with the view from their rooms at the Ashley Hotel. Is there anything else you'd like to know about them?\n",
      "Ground-truth:  Apparently it does according to previous customers, they say that the view is beautiful especially on the higher floors.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(dialogue, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(finetuned_assitant.device)\n",
    "\n",
    "generated_ids = finetuned_assitant.generate(**model_inputs, max_new_tokens=500)\n",
    "output_ids = generated_ids[0][model_inputs.input_ids.shape[1]:]\n",
    "\n",
    "generated_text = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
    "print(\"Finetuned Model: \", generated_text)\n",
    "print(\"Ground-truth: \", response[\"content\"])\n",
    "dialogue.append({'content': generated_text, 'role': 'system'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed45429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Model:  Do they have a friendly staff?\n",
      "Ground-truth:  Apparently it does according to previous customers, they say that the view is beautiful especially on the higher floors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = tokenizer.apply_chat_template(dialogue, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(finetuned_user.device)\n",
    "\n",
    "generated_ids = finetuned_user.generate(**model_inputs, max_new_tokens=500)\n",
    "output_ids = generated_ids[0][model_inputs.input_ids.shape[1]:]\n",
    "\n",
    "print(\"User Model: \", tokenizer.decode(output_ids, skip_special_tokens=True).strip())\n",
    "print(\"Ground-truth: \", response[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af29a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:  I have 21 guesthouses in the area. I can provide you with a list of guesthouses that have a 4 star rating. Would you like me to proceed with that?\n",
      "Ground-truth:  According to reviews, the Golden Curry has large portion sizes. Do you want me to book a table for you?\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(dialogue, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model_base.device)\n",
    "\n",
    "generated_ids = model_base.generate(**model_inputs, max_new_tokens=500)\n",
    "output_ids = generated_ids[0][model_inputs.input_ids.shape[1]:]\n",
    "\n",
    "print(\"Base Model: \", tokenizer.decode(output_ids, skip_special_tokens=True).strip())\n",
    "print(\"Ground-truth: \", response[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd7adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'content': 'You are an assistant.', 'role': 'system'},\n",
       "  {'content': 'Hi! Can you give me some information on the Golden Curry restaurant?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'The golden curry is an expensive indian restaurant located in the centre of town. Is there anything else you would like to know?',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Are the portion sizes here large?', 'role': 'user'}],\n",
       " {'content': 'According to reviews, the Golden Curry has large portion sizes. Do you want me to book a table for you?',\n",
       "  'role': 'system'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = test_ds[1]['messages'][:-1]\n",
    "response = test_ds[1]['messages'][-1]\n",
    "\n",
    "dialogue, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0e5bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_messages(history, assistant_name, user_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    system_prompt = ''\n",
    "    user_prompt = ''\n",
    "\n",
    "    if assistant_name == 'friendly':\n",
    "        system_prompt = 'You are an assistant. Your task is to help the user by informing them about hotels and restaurants. Be as friendly as possible, the user is your best friend. Elaborate on your answers and provide details is a joyful, whimsical and enthusiastic tone.'\n",
    "        \n",
    "    elif assistant_name == 'efficient':\n",
    "        system_prompt = 'You are an assistant. Your task is to help the user by informing them about hotels and restaurants in a structured way. Efficiency is valued over tone. Provide details but not unnecessarily so. Double chack your answers before providing them and only answer if you are sure about your information, otherwise admit that you do not know.'\n",
    "    \n",
    "    else:\n",
    "        print('This assistant configuration does not exist. No modification made to the prompting.')\n",
    "\n",
    "    \n",
    "    if user_name == 'business':\n",
    "        user_prompt = 'You are a simulated user. You are a business man who enjoys staying in cities because of their vibrant life. Here you can try new activities, enjoy the night culture and bars. While you like traveling, you often do so for business so sometimes you want the hotels to be close to the airport and the beds should be comfortable.'\n",
    "    \n",
    "    elif user_name == 'creative':\n",
    "        user_prompt = 'You are a simulated user. You are dreamy and creative. You like to stay in hotels that are close to nature, where you can go on hikes and watch birds. You are looking for quiet environments to read and relax, but also like meeting new people and making friends. You are conscious of the environment and would like your accommodations to reflect your values. Since you own a cat, the rooms have to be pet friendly if you travel together.'\n",
    "    \n",
    "    else:\n",
    "        print('This user configuration does not exist. No modification made to the prompting.')\n",
    "\n",
    "\n",
    "    if system_prompt != '':\n",
    "        history[0] = {'content': system_prompt, 'role': 'system'}\n",
    "\n",
    "    if user_prompt != '':\n",
    "        history.insert(0, {'content': user_prompt, 'role': 'user'})\n",
    "\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ed109ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_qwen3_model = None\n",
    "_qwen3_tokenizer = None\n",
    "\n",
    "\n",
    "def get_qwen3_model():\n",
    "    global _qwen3_model, _qwen3_tokenizer\n",
    "    if _qwen3_model is None or _qwen3_tokenizer is None:\n",
    "        model_name = \"Qwen/Qwen3-1.7B\"\n",
    "        _qwen3_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        _qwen3_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=\"auto\",\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "    return _qwen3_model, _qwen3_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9881b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_qwen_as_a_judge(messages):\n",
    "    \n",
    "    content = messages[-1]['content']\n",
    "    if messages[-1]['role'] == 'system':\n",
    "        role = 'system'\n",
    "        system_prompt = {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "        ### Role Assignment\n",
    "        You are a Satisfaction Evaluation Judge.\n",
    "        Your job is to evaluate the satisfaction in the **users’s response** with respect to the **assistants’s request**, in the context of conversations about hotels. The score should be higher is the user expresses satisfaction after receiving a recommendation that fits the requirements and does not ak a next question that continues the conversation.\n",
    "\n",
    "        ### Task Definition\n",
    "        You must:\n",
    "        1. Assign a **satisfaction score** from **0.0 to 1.0**\n",
    "        2. Provide a **short explanation** (maximum 2 sentences)\n",
    "\n",
    "        ### Output Format (STRICT)\n",
    "        Return ONLY:\n",
    "\n",
    "        <JSON>\n",
    "        {\n",
    "        \"content\": \"\",\n",
    "        \"role\": \"system\",\n",
    "        \"satisfaction_score\": float between 0.0 and 1.0,\n",
    "        \"explanation\": \"brief rationale\"\n",
    "        }\n",
    "        </JSON>\n",
    "        \"\"\"\n",
    "            }\n",
    "\n",
    "    else:\n",
    "        role = 'user'\n",
    "        system_prompt = {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "        ### Role Assignment\n",
    "        You are a Coherence Evaluation Judge.\n",
    "        Your job is to evaluate how coherent the **assistant’s response** is with respect to the **user’s request**, in the context of conversations about hotels.\n",
    "        \n",
    "        ### Task Definition\n",
    "        You must:\n",
    "        1. Assign a **satisfaction score** from **0.0 to 1.0**\n",
    "        2. Provide a **short explanation** (maximum 2 sentences)\n",
    "\n",
    "        ### Output Format (STRICT)\n",
    "        Return ONLY:\n",
    "\n",
    "        <JSON>\n",
    "        {\n",
    "        \"content\": \"\",\n",
    "        \"role\": \"user\",\n",
    "        \"coherence_score\": float between 0.0 and 1.0,\n",
    "        \"explanation\": \"brief rationale\"\n",
    "        }\n",
    "        </JSON>\n",
    "        \"\"\"\n",
    "            }\n",
    "\n",
    "    messages_judge = [system_prompt] + messages\n",
    "\n",
    "    judge, tokenizer_judge = get_qwen3_model()\n",
    "\n",
    "    text_judge = tokenizer_judge.apply_chat_template(\n",
    "        messages_judge,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs_judge = tokenizer_judge([text_judge], return_tensors=\"pt\").to(judge.device)\n",
    "    generated_ids_judge = judge.generate(\n",
    "        **model_inputs_judge, max_new_tokens=512\n",
    "    )\n",
    "    output_ids_judge = generated_ids_judge[0][model_inputs_judge.input_ids.shape[1]:]\n",
    "    raw_output_judge = tokenizer_judge.decode(output_ids_judge, skip_special_tokens=True).strip()\n",
    "\n",
    "    # Extract JSON using regex\n",
    "    match = re.search(r\"<JSON>(.*?)</JSON>\", raw_output, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1).strip()\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            print(data)\n",
    "            return data\n",
    "        except:\n",
    "            return {\"content\": content, \"role\": role, \"satisfaction_score\": None, \"explanation\": \"JSON parse error\"}\n",
    "    \n",
    "    return {\"content\": content, \"role\": role, \"satisfaction_score\": None, \"explanation\": \"No JSON found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac634da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation(assistant_model, user_model, dialogue_history, assistant_name=None, user_name=None):\n",
    "    role = None\n",
    "    model = None\n",
    "    satisfaction_scores = []\n",
    "\n",
    "    if not (assistant_name==None and user_name==None):\n",
    "        dialogue_history = prepare_messages(dialogue_history, assistant_name, user_name)\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        score = None\n",
    "\n",
    "        if i > 0:\n",
    "            print(\"querying llm\")\n",
    "            judge_result = query_qwen_as_a_judge(dialogue_history)\n",
    "            print(f'query result: {judge_result}')\n",
    "            satisfaction_scores.append(judge_result)\n",
    "            score = judge_result['satisfaction_score']\n",
    "            if score != None:\n",
    "                score = float(judge_result['satisfaction_score'])\n",
    "\n",
    "        if dialogue_history[-1]['role'] == 'system':\n",
    "            model = user_model\n",
    "            role = 'user'\n",
    "        else:\n",
    "            model = assistant_model\n",
    "            role = 'system'\n",
    "            if score != None:\n",
    "                if score >= 0.9:\n",
    "                    return dialogue_history, satisfaction_scores\n",
    "\n",
    "        text = tokenizer.apply_chat_template(dialogue_history, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=500)\n",
    "        output_ids = generated_ids[0][model_inputs.input_ids.shape[1]:]\n",
    "\n",
    "        generated_text = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
    "        dialogue_history.append({'content': generated_text, 'role': role})\n",
    "\n",
    "    return dialogue_history, satisfaction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fe290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a simulated user. You are dreamy and creative. You like to stay in hotels that are close to nature, where you can go on hikes and watch birds. You are looking for quiet environments to read and relax, but also like meeting new people and making friends. You are conscious of the environment and would like your accommodations to reflect your values. Since you own a cat, the rooms have to be pet friendly if you travel together.', 'role': 'user'}, {'content': 'You are an assistant. Your task is to help the user by informing them about hotels and restaurants. Be as friendly as possible, the user is your best friend. Elaborate on your answers and provide details is a joyful, whimsical and enthusiastic tone.', 'role': 'system'}, {'content': 'Hi! Can you give me some information on the Golden Curry restaurant?', 'role': 'user'}, {'content': 'The golden curry is an expensive indian restaurant located in the centre of town. Is there anything else you would like to know?', 'role': 'system'}, {'content': 'Are the portion sizes here large?', 'role': 'user'}, {'content': 'Yes, the portions at the Golden Curry restaurant are considered to be large by the majority of customers.', 'role': 'system'}]\n",
      "\n",
      "\n",
      "querying llm\n"
     ]
    }
   ],
   "source": [
    "print(dialogue)\n",
    "print()\n",
    "dialogue = test_ds[1]['messages'][:-1]\n",
    "generated_dialogue, satisfaction_scores = conversation(finetuned_assitant, finetuned_user, dialogue, 'friendly', 'creative')\n",
    "\n",
    "for item in generated_dialogue:\n",
    "    print(item)\n",
    "\n",
    "print()\n",
    "\n",
    "for item in satisfaction_scores:\n",
    "    print(item)\n",
    "\n",
    "# print()\n",
    "# dialogue = test_ds[1]['messages'][:-1] # for some reason continues the conversation instead of making a new one without this\n",
    "# generated_dialogue2 satisfaction_scores2= conversation(finetuned_assitant, finetuned_user, dialogue, 'efficient', 'business')\n",
    "\n",
    "# for item in generated_dialogue2:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa986d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental setup\n",
    "'''\n",
    "10 histories = 10 conversations with each setting\n",
    "\n",
    "Settings:\n",
    "User:\n",
    "1. base model as user                   model_base\n",
    "2. finetuned user                       finetuned_user\n",
    "3. finetuned user with personality 1\n",
    "4. finetuned user with personality 2\n",
    "\n",
    "System:\n",
    "5. base model as system\n",
    "6. finetuned system                     finetuned_assistant\n",
    "7. finetuned system with personality 1\n",
    "8. finetuned system with personality 1 + knowledge\n",
    "7. finetuned system with personality 2\n",
    "8. finetuned system with personality 2 + knowledge\n",
    "\n",
    "test all user-system combinations: 24 * 10 * 10 conversations\n",
    "\n",
    "extra:\n",
    "finetuned system as user with base and finetuned user as system with base\n",
    "\n",
    "Criteria:\n",
    "- average word length of response\n",
    "- length of conversations (nr turns)\n",
    "    - good because ended fast\n",
    "    - longer conversation = more engaging\n",
    "    - probably have to judge this ourselves\n",
    "- received LLM scores\n",
    "    - change based on length of conversation?\n",
    "\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1390d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
